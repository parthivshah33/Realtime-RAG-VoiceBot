{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Voice based conversational bot with pdf knowledge\\vbvenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv, dotenv_values\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model='gemini-pro', google_api_key=os.getenv(\"GEMINI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"**Role of MS Dhoni in India's 2011 ICC Men's Cricket World Cup Victory:**\\n\\n**1. Captaincy and Leadership:**\\n\\n* Dhoni led the Indian team with exceptional composure and strategic decision-making throughout the tournament.\\n* He motivated and inspired his players, fostering a winning mindset and team spirit.\\n\\n**2. Match-Winning Performances:**\\n\\n* Dhoni played several crucial innings, including an unbeaten 91 in the final against Sri Lanka.\\n* His ability to finish games under pressure was instrumental in India's victories.\\n\\n**3. Wicketkeeping and Run-Outs:**\\n\\n* Dhoni was an exceptional wicketkeeper, with lightning-fast reflexes and accurate throws.\\n* His run-outs, particularly in the semi-final against Pakistan, proved decisive moments.\\n\\n**4. Strategic Field Placements:**\\n\\n* Dhoni's astute field placements and bowling changes often outwitted the opposition.\\n* He effectively used his fielders to cut off scoring opportunities and create pressure on batsmen.\\n\\n**5. Psychological Warfare:**\\n\\n* Dhoni's calm demeanor and ability to stay focused under pressure played a psychological role.\\n* He often engaged in subtle mind games with the opposition, unsettling their rhythm.\\n\\n**6. Decisive Decision-Making:**\\n\\n* Dhoni's ability to make quick and decisive decisions in crucial moments was vital.\\n* His decision to bat first in the final, despite losing the toss, paid off handsomely.\\n\\n**7. Team Bonding:**\\n\\n* Dhoni fostered a strong bond within the team, creating a sense of unity and purpose.\\n* He ensured that all players felt valued and contributed to the team's success.\\n\\n**Overall, MS Dhoni's exceptional leadership, match-winning performances, and strategic brilliance played a pivotal role in India's historic victory in the 2011 ICC Men's Cricket World Cup.**\", response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-114bd7fb-7a46-442d-8e70-1b6abbcd1707-0')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"how MSDHONI made india won 2011 ICC Men's Cricket World cup?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PDF to chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "pdf_path = (\"D:\\Voice based conversational bot with pdf knowledge\\knowledge documents\\machine_learning_tutorial.pdf\")\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "chunk_size = 800\n",
    "chunk_overlap = 80\n",
    "length_function = len\n",
    "is_separator_regex = False\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    length_function=length_function,\n",
    "    is_separator_regex=is_separator_regex\n",
    ")\n",
    "\n",
    "doc_chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='i', metadata={'source': 'D:\\\\Voice based conversational bot with pdf knowledge\\\\knowledge documents\\\\machine_learning_tutorial.pdf', 'page': 0})]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_chunks = doc_chunks[:1]\n",
    "doc_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "source": [
    "Google Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embedding_client = GoogleGenerativeAIEmbeddings(\n",
    "    model=\"models/text-embedding-004\", task_type=\"retrieval_document\", google_api_key=\"AIzaSyB67yE_ZKd5BKhLluTEi767CzzALRzt-4Q\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='i', metadata={'source': 'D:\\\\Voice based conversational bot with pdf knowledge\\\\knowledge documents\\\\machine_learning_tutorial.pdf', 'page': 0})]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding document chunks: 100%|██████████| 1/1 [00:01<00:00,  1.85s/chunk]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing chunks along with metadata in ChromaDB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "docs = []\n",
    "metadatas = []\n",
    "ids = []\n",
    "embeddings = []\n",
    "\n",
    "for chunk in tqdm(doc_chunks, desc=\"Embedding document chunks\", unit=\"chunk\"):\n",
    "    # Embed the batch of document chunks\n",
    "    embedding = embedding_client.embed_query(chunk.page_content)\n",
    "    # Append the embeddings of the current batch to the final list\n",
    "    embeddings.append(embedding)\n",
    "\n",
    "    print(\"Storing chunks along with metadata in ChromaDB\")\n",
    "    for i, chunk in enumerate(doc_chunks):\n",
    "        docs.append(chunk.page_content)      # Append document chunk text\n",
    "        # Append metadata (e.g., page number)\n",
    "        metadatas.append(chunk.metadata)\n",
    "        # Append unique identifier for each chunk\n",
    "        ids.append(f\"chunk_{i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists: D:\\Voice based conversational bot with pdf knowledge\\data\\chroma\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the 'data/chroma' directory relative to the project root\n",
    "persist_directory = r\"D:\\Voice based conversational bot with pdf knowledge\\data\\chroma\"\n",
    "\n",
    "if not os.path.exists(persist_directory):\n",
    "    os.makedirs(persist_directory)\n",
    "    print(f\"Directory created: {persist_directory}\")\n",
    "else:\n",
    "    print(f\"Directory already exists: {persist_directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<chromadb.api.client.Client object at 0x0000027B10846C40> chroma client made at D:\\Voice based conversational bot with pdf knowledge\\data\\chroma\n"
     ]
    }
   ],
   "source": [
    "chroma_client = chromadb.PersistentClient(path=str(persist_directory))\n",
    "print(f\"{chroma_client} chroma client made at {str(persist_directory)}\")\n",
    "collection_name = \"rag_aiml_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChromaDB Collection has been build!, collection object : Collection(id=9ce8f329-9852-42d6-83e1-f52917a34e72, name=rag_aiml_data)\n"
     ]
    }
   ],
   "source": [
    "collection = chroma_client.get_or_create_collection(\n",
    "    name=collection_name)\n",
    "\n",
    "print(f\"ChromaDB Collection has been build!, collection object : {collection}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________starting adding embeddings to Collection(id=9ce8f329-9852-42d6-83e1-f52917a34e72, name=rag_aiml_data)___________\n",
      "==============================\n",
      "Data is stored in ChromaDB.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(f\"___________starting adding embeddings to {collection}___________\")\n",
    "    collection.add(\n",
    "        documents=docs,\n",
    "        metadatas=metadatas,\n",
    "        embeddings=embeddings,\n",
    "        ids=ids\n",
    "    )\n",
    "    print(\"==============================\")\n",
    "    print(\"Data is stored in ChromaDB.\")\n",
    "except:\n",
    "    print(\"---Failed to add data to chroma collection---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using PINECONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PINECONE_API_KEY : 29dad76e-dc0c-4a43-b876-b5bdd748601c\n",
      "PINECONE_API_ENV : us-east-1\n",
      "PINECONE_INDEX_NAME : voicebot\n"
     ]
    }
   ],
   "source": [
    "PINECONE_API_KEY = \"29dad76e-dc0c-4a43-b876-b5bdd748601c\"\n",
    "PINECONE_API_ENV = \"us-east-1\"\n",
    "pinecone_index_name = \"voicebot\"\n",
    "print(f\"PINECONE_API_KEY : {PINECONE_API_KEY}\")\n",
    "print(f\"PINECONE_API_ENV : {PINECONE_API_ENV}\")\n",
    "print(f\"PINECONE_INDEX_NAME : {pinecone_index_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "import os\n",
    "import joblib\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing Vectors to Remote space of Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore_from_docs = PineconeVectorStore.from_documents(\n",
    "    doc_chunks,\n",
    "    index_name=pinecone_index_name,\n",
    "    embedding=embedding_client\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Querying Pinecone remotely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "index = pc.Index(pinecone_index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"what is machine learning?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeded_query = embedding_client.embed_query(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_chunks = index.query(\n",
    "    vector=embeded_query,\n",
    "    top_k=10,\n",
    "    include_metadata=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata_dict = retrieved_chunks['metadata']\n",
    "# pages = retrieved_chunks['metadata']['page']\n",
    "# source = retrieved_chunks['metadata']['source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimization techniques to find the best solution to your problem.  \n",
      " \n",
      "Next,  let us look at the different categories of Machine Learning.\n"
     ]
    }
   ],
   "source": [
    "print(retrieved_chunks['matches'][0]['metadata']['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAGE NUMBER 0----->  i \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrieval_text = []\n",
    "for i, retrieved_chunk in enumerate(retrieved_chunks.matches):\n",
    "    print(\n",
    "        f\"PAGE NUMBER {i}----->  {retrieved_chunk['metadata']['text']} \\n\\n\\n\")\n",
    "\n",
    "    retrieval_text.append(retrieved_chunk['metadata']['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_text = ''.join(retrieval_text)\n",
    "retrieval_text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
